{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\helloliuzw\\\\Desktop\\\\Career_Platform\\\\classifier', 'C:\\\\ProgramData\\\\Anaconda3\\\\python38.zip', 'C:\\\\ProgramData\\\\Anaconda3\\\\DLLs', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\ProgramData\\\\Anaconda3', '', 'C:\\\\Users\\\\helloliuzw\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\helloliuzw\\\\.ipython', 'C:\\\\Users\\\\helloliuzw\\\\Desktop\\\\Career_Platform\\\\', 'C:\\\\Users\\\\helloliuzw\\\\Desktop\\\\']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\helloliuzw\\\\Desktop\\\\Career_Platform\\\\')\n",
    "sys.path.append('C:\\\\Users\\\\helloliuzw\\\\Desktop\\\\')\n",
    "print(sys.path)\n",
    "from Career_Platform.parser.label_classifier import KGClassifier,ExpRuleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['深圳', '市政府直属']\n",
      "***********\n"
     ]
    }
   ],
   "source": [
    "kgc = KGClassifier()\n",
    "rulec = ExpRuleClassifier()\n",
    "test_text = ['深圳 美都美容美发足浴公司 党支部 书记',\n",
    " '驻 香港 部队 步兵旅 司令部 作训 科长',\n",
    " '深圳市人民政府 办公厅 社会 一处 主任科员',\n",
    " '深圳市公安局 法制 处 四级 警长',\n",
    " '四川 煤炭 第一 建筑工程 公司 技术员 llz',\n",
    " '广州市L 第62中学O 辅导员P'\n",
    "            ]\n",
    "\n",
    "test_text2 = ['广州市L 第62中学O 辅导员P','广州市L 师范学校O 历史科S 学习P','黄埔港务局O 十年制学校O 教师P','局O 宣传科S 干事P','广东省L 纪委科员P']\n",
    "\n",
    "test_text3 = ['深圳市政府办公厅O 副主任科员P']\n",
    "for text in test_text3:\n",
    "    res = kgc.classify(text,True)\n",
    "    res2 = rulec.classify(text)\n",
    "    print(res)\n",
    "    print(res2)\n",
    "    print('***********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great!\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "a = ['深圳']\n",
    "b = True\n",
    "if a and b:\n",
    "    print('great!')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = '深圳L 广州O'\n",
    "result = re.sub('[LOSP]','',text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字典测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obj building Consuming: 0.0019958019256591797 s\n",
      "\n",
      "Sample Text: 清华大学深圳研究院电子通信硕士\n",
      "['双一流大学', '科技技术', '深圳', '理工方向1']\n",
      "Time Consuming: 0.0009996891021728516 s\n",
      "\n",
      "Sample Text: 深圳市 审计局 政府 投资 审计 专业 局 审计 三处 主任科员\n",
      "['深圳']\n",
      "Time Consuming: 0.0 s\n",
      "\n",
      "Sample Text: 深圳市 无线电 管理局 综合处 处长\n",
      "['深圳']\n",
      "Time Consuming: 0.0 s\n",
      "\n",
      "Sample Text: 深圳市 无线电 管理 办公室 业务 处处长\n",
      "['深圳']\n",
      "Time Consuming: 0.0 s\n"
     ]
    }
   ],
   "source": [
    "from SZlabeler.label_classifier import ExpRuleClassifier\n",
    "import os\n",
    "import time\n",
    "location = r'C:\\Users\\helloliuzw\\Desktop\\parser'\n",
    "\n",
    "text1 = '清华大学深圳研究院电子通信硕士'\n",
    "text2 = '深圳市 审计局 政府 投资 审计 专业 局 审计 三处 主任科员'\n",
    "text3 = '深圳市 无线电 管理局 综合处 处长'\n",
    "text4 = '深圳市 无线电 管理 办公室 业务 处处长'\n",
    "\n",
    "t0 = time.time()\n",
    "label = ExpRuleClassifier()\n",
    "print('Obj building Consuming:',time.time()-t0,'s')\n",
    "\n",
    "print('\\nSample Text:',text1)\n",
    "t0 = time.time()\n",
    "print(label.classify(text1))\n",
    "print('Time Consuming:',time.time()-t0,'s')\n",
    "\n",
    "print('\\nSample Text:',text2)\n",
    "t1 = time.time()\n",
    "print(label.classify(text2))\n",
    "print('Time Consuming:',time.time()-t1,'s')\n",
    "\n",
    "print('\\nSample Text:',text3)\n",
    "t1 = time.time()\n",
    "print(label.classify(text3))\n",
    "print('Time Consuming:',time.time()-t1,'s')\n",
    "\n",
    "print('\\nSample Text:',text4)\n",
    "t1 = time.time()\n",
    "print(label.classify(text4))\n",
    "print('Time Consuming:',time.time()-t1,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = {'liu':True,'zw':False,'today':True}\n",
    "q2 = {'here':False}\n",
    "q3 = {'zw':True}\n",
    "q4 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'liu': True, 'zw': False, 'today': True, 'here': False}\n",
      "{'liu': True, 'zw': True, 'today': True}\n",
      "{'liu': True, 'zw': False, 'today': True}\n"
     ]
    }
   ],
   "source": [
    "w = {**q1,**q2}\n",
    "e = {**q1,**q3}\n",
    "r = {**q1,**q4}\n",
    "print(w)\n",
    "print(e)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(w.get('here'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'red': True}\n"
     ]
    }
   ],
   "source": [
    "r = {}\n",
    "r['red'] = True\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A node is defined as:\n",
    "    node_id:[final_output,input_id_list,output_reverse,logic]\n",
    "for leaf node we can note it as:\n",
    "    node_id:[final_output,key,output_reverse,None]\n",
    "'''\n",
    "tree = {'0':[True,[1,2],False,'and'],\n",
    "        '1':[True,[3,4,5],False,'or'],\n",
    "        '2':[True,'科技技术',False,None],\n",
    "        '3':[True,'一般院校',False,None],\n",
    "        '4':[True,'双一流大学',False,None],\n",
    "        '5':[True,'海外名校',False,None]}\n",
    "\n",
    "tree1 = {'0':[True,[1,2],False,'and'],\n",
    "        '1':[True,[3,4,5],True,'and'],\n",
    "        '2':[True,'科技技术',False,None],\n",
    "        '3':[True,'一般院校',True,None],\n",
    "        '4':[True,'双一流大学',True,None],\n",
    "        '5':[True,'海外名校',True,None]}\n",
    "\n",
    "tree2 = {'0':[True,'法务纪检',False,None]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: True\n",
      "Python Expression: ((result_dict[\"一般院校\"] or result_dict[\"双一流大学\"] or result_dict[\"海外名校\"]) and result_dict[\"科技技术\"])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: logic tree Pages: 1 -->\r\n",
       "<svg width=\"349pt\" height=\"260pt\"\r\n",
       " viewBox=\"0.00 0.00 348.89 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\r\n",
       "<title>logic tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-256 344.892,-256 344.892,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"216.446\" cy=\"-90\" rx=\"27.8951\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"216.446\" y=\"-86.3\" font-family=\"Microsoft YaHei\" font-size=\"14.00\">and</text>\r\n",
       "</g>\r\n",
       "<!-- output -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>output</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"216.446\" cy=\"-18\" rx=\"40.8928\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"216.446\" y=\"-14.3\" font-family=\"Microsoft YaHei\" font-size=\"14.00\">output</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;output -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>0&#45;&gt;output</title>\r\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M216.446,-71.6966C216.446,-63.9827 216.446,-54.7125 216.446,-46.1124\"/>\r\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"219.946,-46.1043 216.446,-36.1043 212.946,-46.1044 219.946,-46.1043\"/>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"170.446\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"170.446\" y=\"-158.3\" font-family=\"Microsoft YaHei\" font-size=\"14.00\">or</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;0 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>1&#45;&gt;0</title>\r\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M180.884,-145.116C186.648,-136.345 193.93,-125.264 200.401,-115.416\"/>\r\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"203.482,-117.1 206.049,-106.821 197.632,-113.256 203.482,-117.1\"/>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"262.446\" cy=\"-162\" rx=\"47.3916\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"262.446\" y=\"-158.3\" font-family=\"Microsoft YaHei\" font-size=\"14.00\">科技技术</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;0 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>2&#45;&gt;0</title>\r\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M251.544,-144.411C245.849,-135.744 238.77,-124.971 232.464,-115.375\"/>\r\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"235.369,-113.423 226.952,-106.988 229.519,-117.267 235.369,-113.423\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"47.4458\" cy=\"-234\" rx=\"47.3916\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"47.4458\" y=\"-230.3\" font-family=\"Microsoft YaHei\" font-size=\"14.00\">一般院校</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;1 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>3&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M72.6335,-218.666C92.7149,-207.237 120.844,-191.229 141.785,-179.311\"/>\r\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"143.6,-182.305 150.56,-174.317 140.138,-176.222 143.6,-182.305\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"170.446\" cy=\"-234\" rx=\"57.3905\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"170.446\" y=\"-230.3\" font-family=\"Microsoft YaHei\" font-size=\"14.00\">双一流大学</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;1 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>4&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M170.446,-215.697C170.446,-207.983 170.446,-198.712 170.446,-190.112\"/>\r\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"173.946,-190.104 170.446,-180.104 166.946,-190.104 173.946,-190.104\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"293.446\" cy=\"-234\" rx=\"47.3916\" ry=\"18\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"293.446\" y=\"-230.3\" font-family=\"Microsoft YaHei\" font-size=\"14.00\">海外名校</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;1 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>5&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M268.258,-218.666C248.177,-207.237 220.048,-191.229 199.107,-179.311\"/>\r\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"200.754,-176.222 190.332,-174.317 197.292,-182.305 200.754,-176.222\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x2263886edc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import re\n",
    "from SZlabeler.logic_tree import logictree\n",
    "\n",
    "# result_d = {'一般院校':False,'双一流大学':True,'海外名校':False,'科技技术':True,'深圳':False}\n",
    "# result_d = {'一般院校':False,'双一流大学':False,'海外名校':False,'科技技术':True,'深圳':False}\n",
    "# result_d = {'一般院校':False,'双一流大学':True,'海外名校':False,'科技技术':False,'深圳':False}\n",
    "result_d = {'一般院校':False,'双一流大学':False,'海外名校':True,'科技技术':True,'法务纪检':True,'深圳':True}\n",
    "\n",
    "ltree = logictree(tree,result_d)\n",
    "print('Final output:',ltree.getvalue())\n",
    "print('Python Expression:',ltree.tree2exp())\n",
    "ltree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:请合理使用小括号，同一小括号内，and、or、not三类关键字仅出现其中一类；\n",
      "正确实例 ：(\"教育\" and (not \"科技\") and (\"经济\" or \"行政\"))\n",
      "错误示例1：(\"教育\" and not \"科技\" and (\"经济\" or \"行政\"))\n",
      "错误示例2：(\"教育\" and (not \"科技\") and ((\"经济\" or \"行政\")))\n"
     ]
    }
   ],
   "source": [
    "testtree = logictree(ltree.exp2tree('()'))\n",
    "# testtree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxgrade 4\n",
      "grade 0\n",
      "depthtree {'1': [[0, [], '(科技 and ((not (人文 or 机械)) and ((法律 or 纪检) and 深圳)) and 交通)']], '2': [[1, [], '((not (人文 or 机械)) and ((法律 or 纪检) and 深圳))']], '3': [[2, [], '((法律 or 纪检) and 深圳)'], [4, [], '(not (人文 or 机械))']], '4': [[3, [], '(法律 or 纪检)'], [5, [], '(人文 or 机械)']]}\n",
      "depthtree {'1': [[0, [1], '(科技 and  and 交通)']], '2': [[1, [2, 4], '( and )']], '3': [[2, [3], '( and 深圳)'], [4, [5], '(not )']], '4': [[3, [], '(法律 or 纪检)'], [5, [], '(人文 or 机械)']]}\n",
      "nodelist [[0, [1], '(科技 and  and 交通)'], [1, [2, 4], '( and )'], [2, [3], '( and 深圳)'], [4, [5], '(not )'], [3, [], '(法律 or 纪检)'], [5, [], '(人文 or 机械)']]\n",
      "['交通', '科技']\n",
      "[]\n",
      "['深圳']\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-66c807d13121>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchildL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnotflag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mchildL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnotflag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mtree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnotflag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogic\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# expression 2 tree\n",
    "\n",
    "expression = '(科技 and ((not 人文) and ((法律 or 纪检) and 深圳)) and 交通)'\n",
    "if not expression.startswith('('):\n",
    "    expression = '('+expression+')'\n",
    "Llist = []\n",
    "grade,maxgrade = 0,0\n",
    "allnode = []\n",
    "for i,ch in enumerate(expression):\n",
    "    if ch=='(':\n",
    "        Llist.append(i)\n",
    "        grade += 1\n",
    "    elif ch==')':\n",
    "        maxgrade = max(grade,maxgrade)\n",
    "        allnode.append([grade,expression[Llist.pop():i+1]])\n",
    "        grade -= 1\n",
    "allnode.reverse()\n",
    "print('maxgrade',maxgrade)\n",
    "print('grade',grade)\n",
    "# allnode get, now depth tree\n",
    "depthtree = {}\n",
    "for i in range(1,maxgrade+1):\n",
    "    depthtree[str(i)] = []\n",
    "for i,node in enumerate(allnode):\n",
    "    depthtree[str(node[0])].append([i,[],node[1]])\n",
    "print('depthtree',depthtree)\n",
    "# depthtree\n",
    "for dep in range(1,maxgrade):\n",
    "    for par in depthtree[str(dep)]:\n",
    "        for chi in depthtree[str(dep+1)]:\n",
    "            if chi[2] in par[2]:\n",
    "                par[1].append(chi[0])\n",
    "                par[2] = par[2].replace(chi[2],'',1)\n",
    "print('depthtree',depthtree)                \n",
    "# Real tree\n",
    "nodelist = []\n",
    "for L in depthtree.values():\n",
    "    nodelist.extend(L)\n",
    "print('nodelist',nodelist)\n",
    "nodenum = len(nodelist)\n",
    "tree = {}\n",
    "for node in nodelist:\n",
    "    node[2] = node[2][1:-1]\n",
    "    parsed = node[2].split()\n",
    "    notflag = False\n",
    "    for operator in ['and','or']:\n",
    "        if operator in parsed:\n",
    "            logic = operator\n",
    "            childL = node[2].split(' '+operator+' ')\n",
    "    if 'not' in parsed:\n",
    "        logic = 'None'\n",
    "        notflag = True\n",
    "        childL = node[2].split('not ')\n",
    "    childL = [item.strip() for item in childL]\n",
    "    childL = list(set(childL))\n",
    "    if '' in childL:\n",
    "        childL.remove('')\n",
    "    print(childL)\n",
    "    if notflag == True:\n",
    "        tree[str(node[0])] = [True,childL[0],notflag,None]\n",
    "        continue\n",
    "    tree[str(node[0])] = [True,node[1],notflag,logic]\n",
    "    for source in childL:\n",
    "        tree[str(node[0])][1].append(nodenum)\n",
    "        tree[str(nodenum)] = [True,source,notflag,None]\n",
    "        nodenum += 1\n",
    "    \n",
    "print('tree',tree)\n",
    "allnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = logictree(tree,result_d)\n",
    "# lo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "er = '(5 and node and 6)'[1:-1]\n",
    "print(type(er))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None or True = True\n",
      "None or False = False\n",
      "None and True = None\n",
      "None and False = None\n",
      "not None = True\n"
     ]
    }
   ],
   "source": [
    "None1 = None or True\n",
    "None11 = None or False\n",
    "None2 = None and True\n",
    "None22 = None and False\n",
    "None3 = not None\n",
    "print('None or True =',None1)\n",
    "print('None or False =',None11)\n",
    "print('None and True =',None2)\n",
    "print('None and False =',None22)\n",
    "print('not None =',None3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KG clf测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from gensim.models import Word2Vec,KeyedVectors,FastText\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import re,os,pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = os.path.abspath(os.path.dirname(__file__))\n",
    "\n",
    "class LabelClassifier:\n",
    "    def __init__(self,label_dict_path=location+'/../data/labels.txt'):\n",
    "        self.labeldict = {}  # dictionary that maps int to label text\n",
    "        self.labeldictR = {} # maps label text to int\n",
    "        self.load_label_dict(label_dict_path)\n",
    "        #print(self.labeldictR)\n",
    "\n",
    "    def load_label_dict(self,filename):\n",
    "        with open(filename,encoding='UTF-8') as f:\n",
    "            data = f.read().splitlines()\n",
    "        self.labeldict = { i:a.split('\\t')[0] for (i,a) in enumerate(data)}\n",
    "        self.labeldictR = { a:i  for (i,a) in self.labeldict.items()}\n",
    "    # abstract function to be reimplemented in subclasses.\n",
    "    def classify(self,string):\n",
    "        pass\n",
    "    # abstract function to be reimplemented in subclasses.\n",
    "    def train_update(self, list_mseg, list_mlabel):\n",
    "        pass\n",
    "    \n",
    "class KGClassifier(LabelClassifier):\n",
    "    '''Object Initial'''\n",
    "    def __init__(self, label2id_path = location+'/config/labels.txt'):\n",
    "        LabelClassifier.__init__(self)\n",
    "        self.label2id = {}\n",
    "        with open(label2id_path,'r') as f:\n",
    "            label2id = f.readlines()\n",
    "        for line in label2id:\n",
    "            line = line.strip().split('\\t')\n",
    "            self.label2id[line[0]] = eval(line[1])\n",
    "        self.id2label = []\n",
    "        for key in self.label2id:\n",
    "            self.id2label.append(key)\n",
    "        self.loadKGE()\n",
    "    '''Save and Load KG embeddings'''\n",
    "    def loadKGE(self,Model_path = 'model/kge1.txt'):\n",
    "        with open(Model_path,'rb') as f:\n",
    "            self.Mymodel = pickle.load(f)\n",
    "        f.close()\n",
    "    def saveKGE(self,Model_path='model/kge_'+time.strftime(\"%Y-%m-%d_%H_%M\", time.localtime()) +'.kge'):\n",
    "        f = open(Model_path,'wb')\n",
    "        pickle.dump(self.Mymodel,f)\n",
    "        f.close()\n",
    "    '''online-train kge'''\n",
    "    def online_train_kge(self,L,learning_rate=0.0005,epoch_size=10,saving=False):\n",
    "        '''L sample:[['深圳市 公安局 警员',['公安','深圳']],['广州市 环保局 科员',['环境保护']],…]'''\n",
    "        allfacts = []\n",
    "        for resu in L:\n",
    "            text,labels = resu\n",
    "            for label in labels:\n",
    "                allfacts.append(text+'\\ttext.2.label\\t'+label+'\\n')\n",
    "            for item in text.split():\n",
    "                if item not in self.Mymodel:\n",
    "                    self.Mymodel[item] = torch.Tensor(np.random.rand(len(self.Mymodel['深圳'])))\n",
    "                    self.Mymodel[item].requires_grad = True\n",
    "        LossList = []\n",
    "        parameter = {**self.Mymodel}.values()\n",
    "        optimizer = optim.SGD(parameter,lr=learning_rate)\n",
    "        batch_size = 1\n",
    "        for epoch in range(epoch_size):\n",
    "            epoch_loss = 0\n",
    "            shuffle(allfacts)\n",
    "            list2 = []\n",
    "            for i in range(0, len(allfacts), batch_size):\n",
    "                list2.append(allfacts[i:i+batch_size])\n",
    "            for sub_batch in list2:\n",
    "                optimizer.zero_grad()\n",
    "                liu = self.Loss(sub_batch)\n",
    "                #print('Epoch',epoch,'- Batch Loss:',liu)\n",
    "                epoch_loss += float(liu)\n",
    "                liu.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "            #print('Epoch',epoch,'finished. Loss:',epoch_loss)\n",
    "            LossList.append(epoch_loss)\n",
    "        if saving == True:\n",
    "            final = {**self.Mymodel}\n",
    "            f = open('model/kge_'+time.strftime(\"%Y-%m-%d_%H_%M\", time.localtime()) +'.kge','wb')\n",
    "            pickle.dump(final,f)\n",
    "            f.close()\n",
    "            \n",
    "    '''PNN online-train kge'''\n",
    "    def PNN_kge(self,L,learning_rate=0.0005,epoch_size=10,saving=False):\n",
    "        '''L sample:[['深圳市 公安局 警员',['公安','深圳']],['广州市 环保局 科员',['环境保护']],…]'''\n",
    "        parameter = {}\n",
    "        \n",
    "        allfacts = []\n",
    "        for resu in L:\n",
    "            text,labels = resu\n",
    "            for label in labels:\n",
    "                allfacts.append(text+'\\ttext.2.label\\t'+label+'\\n')\n",
    "            for item in text.split():\n",
    "                if item not in self.Mymodel:\n",
    "                    self.Mymodel[item] = torch.Tensor(np.random.rand(len(self.Mymodel['深圳'])))\n",
    "                    self.Mymodel[item].requires_grad = True\n",
    "                    parameter = {item:self.Mymodel[item],**parameter}\n",
    "        parameter = {**parameter}.values()\n",
    "\n",
    "        LossList = []\n",
    "        optimizer = optim.SGD(parameter,lr=learning_rate)\n",
    "        batch_size = 1\n",
    "        for epoch in range(epoch_size):\n",
    "            epoch_loss = 0\n",
    "            shuffle(allfacts)\n",
    "            list2 = []\n",
    "            for i in range(0, len(allfacts), batch_size):\n",
    "                list2.append(allfacts[i:i+batch_size])\n",
    "            for sub_batch in list2:\n",
    "                optimizer.zero_grad()\n",
    "                liu = self.Loss(sub_batch)\n",
    "                #print('Epoch',epoch,'- Batch Loss:',liu)\n",
    "                epoch_loss += float(liu)\n",
    "                liu.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "            #print('Epoch',epoch,'finished. Loss:',epoch_loss)\n",
    "            LossList.append(epoch_loss)\n",
    "        if saving == True:\n",
    "            final = {**self.Mymodel}\n",
    "            f = open('model/kge_'+time.strftime(\"%Y-%m-%d_%H_%M\", time.localtime()) +'.kge','wb')\n",
    "            pickle.dump(final,f)\n",
    "            f.close()\n",
    "            \n",
    "    '''CopyWeight with ReInit online-train kge'''\n",
    "    def CWR_kge(self,L,learning_rate=0.0005,epoch_size=10,saving=False):\n",
    "        '''L sample:[['深圳市 公安局 警员',['公安','深圳']],['广州市 环保局 科员',['环境保护']],…]'''\n",
    "        parameter = {}\n",
    "        \n",
    "        allfacts = []\n",
    "        for resu in L:\n",
    "            text,labels = resu\n",
    "            for label in labels:\n",
    "                allfacts.append(text+'\\ttext.2.label\\t'+label+'\\n')\n",
    "            for item in text.split():\n",
    "                if item not in self.Mymodel:\n",
    "                    self.Mymodel[item] = torch.Tensor(np.random.rand(len(self.Mymodel['深圳'])))\n",
    "                    self.Mymodel[item].requires_grad = True\n",
    "                parameter = {item:self.Mymodel[item],**parameter}\n",
    "        parameter = {**parameter}.values()\n",
    "\n",
    "        LossList = []\n",
    "        optimizer = optim.SGD(parameter,lr=learning_rate)\n",
    "        batch_size = 1\n",
    "        for epoch in range(epoch_size):\n",
    "            epoch_loss = 0\n",
    "            shuffle(allfacts)\n",
    "            list2 = []\n",
    "            for i in range(0, len(allfacts), batch_size):\n",
    "                list2.append(allfacts[i:i+batch_size])\n",
    "            for sub_batch in list2:\n",
    "                optimizer.zero_grad()\n",
    "                liu = self.Loss(sub_batch)\n",
    "                #print('Epoch',epoch,'- Batch Loss:',liu)\n",
    "                epoch_loss += float(liu)\n",
    "                liu.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "            #print('Epoch',epoch,'finished. Loss:',epoch_loss)\n",
    "            LossList.append(epoch_loss)\n",
    "        if saving == True:\n",
    "            final = {**self.Mymodel}\n",
    "            f = open('model/kge_'+time.strftime(\"%Y-%m-%d_%H_%M\", time.localtime()) +'.kge','wb')\n",
    "            pickle.dump(final,f)\n",
    "            f.close()\n",
    "            \n",
    "    '''utils for kge'''\n",
    "    def kg_text_embd(self,string):\n",
    "        res = string.split()\n",
    "        result = 0\n",
    "        for item in res:\n",
    "            if item not in self.Mymodel:\n",
    "                self.Mymodel[item] = torch.Tensor(np.random.rand(len(self.Mymodel['深圳'])))\n",
    "                self.Mymodel[item].requires_grad = True\n",
    "            result += self.Mymodel[item]\n",
    "        doc_embedding = result/len(res)\n",
    "        return doc_embedding\n",
    "    def TransE(self,he,re,te):\n",
    "        score =  torch.norm(he+re-te)\n",
    "        return score\n",
    "    def Loss(self,L):\n",
    "        loss = 0\n",
    "        for fact in L:\n",
    "            h,r,t = fact.strip().split('\\t')\n",
    "            he = self.kg_text_embd(h)\n",
    "            re = self.Mymodel[r]\n",
    "            te = self.kg_text_embd(t)\n",
    "            loss += self.TransE(he,re,te)\n",
    "        return loss\n",
    "        \n",
    "    def doc_emb1(self,s):\n",
    "        s = s.split()\n",
    "        result = 0\n",
    "        for item in s:\n",
    "            result += self.Mymodel[item].detach().numpy()\n",
    "        return result/len(s)\n",
    "        \n",
    "    def loaddata(self,text_path = location+'/../../data/Corpus.txt',name_path = location+'/../../data/powerset.txt'):\n",
    "        with open(text_path,'r') as f:\n",
    "            texts = f.readlines()\n",
    "        f.close()\n",
    "        with open(name_path,'r') as g:\n",
    "            names = g.readlines()\n",
    "        g.close()\n",
    "        self.x_train = []\n",
    "        self.x_test = []\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        for i in range(len(texts)):\n",
    "            _,flag,labels = names[i].split('\\t',2)\n",
    "            labels = eval(labels)\n",
    "            labels = [self.label2id[x] for x in labels]\n",
    "            y = np.zeros(len(self.id2label))\n",
    "            for ind in labels:\n",
    "                y[ind] = 1\n",
    "            if flag == 'train':\n",
    "                self.x_train.append(texts[i].strip())\n",
    "                self.y_train.append(y)\n",
    "            elif flag == 'test':\n",
    "                self.x_test.append(texts[i].strip())\n",
    "                self.y_test.append(y)\n",
    "        self.y_train = np.array(self.y_train)\n",
    "        self.y_test = np.array(self.y_test)\n",
    "        for i,s in enumerate(self.x_train):\n",
    "            self.x_train[i] = self.doc_emb1(s)\n",
    "        self.x_train = np.array(self.x_train)\n",
    "        for i,s in enumerate(self.x_test):\n",
    "            self.x_test[i] = self.doc_emb1(s)\n",
    "        self.x_test = np.array(self.x_test)\n",
    "    '''Train and online-train clf'''\n",
    "    def trainclf(self):\n",
    "        model = OneVsRestClassifier(svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto'))\n",
    "        self.clf0 = model.fit(self.x_train, self.y_train)\n",
    "    def online_train_clf(self,x_test, y_test):\n",
    "        self.clf0 = self.clf0.partial_fit(x_test, y_test)\n",
    "    '''Save and Load clf model'''\n",
    "    def saveclf(self,path = location+'//model/temp.model'):\n",
    "        with open(path,'wb') as f:\n",
    "            pickle.dump(self.clf0,f)\n",
    "        f.close()\n",
    "    def loadclf(self,path = location+'/model/kg_svc_1.model'):\n",
    "        with open(path,'rb') as f:\n",
    "            self.clf = pickle.load(f)\n",
    "        f.close()\n",
    "    '''Label prediction'''\n",
    "    def classify(self,string):\n",
    "        string = self.doc_emb1(string)\n",
    "        string = [string]\n",
    "        pre = self.clf.predict(string)[0]\n",
    "        result = []\n",
    "        for i,flag in enumerate(pre):\n",
    "            if float(flag) > 0:\n",
    "                result.append(self.id2label[i])\n",
    "        return result\n",
    "    '''Inference and Evaluation'''\n",
    "    def _evaluate(self,x,y):\n",
    "        c = (x + y)[0]\n",
    "        m,n = 0,0\n",
    "        for num in c:\n",
    "            if num > 0.0:\n",
    "                m += 1\n",
    "            if num == 2.0:\n",
    "                n += 1\n",
    "        return n/m\n",
    "    def Accu(self):\n",
    "        self.score = 0\n",
    "        for i in range(self.x_test.shape[0]):\n",
    "            y_predict = self.clf.predict(np.array([self.x_test[i]]))\n",
    "            self.score += self._evaluate(y_predict,self.y_test[i])\n",
    "        self.score = self.score/self.x_test.shape[0]\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['党务工作', '深圳']\n",
      "['深圳市外1']\n",
      "['深圳']\n",
      "['公安', '深圳']\n",
      "['深圳市外1']\n"
     ]
    }
   ],
   "source": [
    "b = KGClassifier()\n",
    "b.loadclf()\n",
    "test_text = ['深圳 美都美容美发足浴公司 党支部 书记',\n",
    " '驻 香港 部队 步兵旅 司令部 作训 科长',\n",
    " '深圳市人民政府 办公厅 社会 一处 主任科员',\n",
    " '深圳市公安局 法制 处 四级 警长',\n",
    " '四川 煤炭 第一 建筑工程 公司 技术员']\n",
    "for text in test_text:\n",
    "    res = b.classify(text)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_values' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bc9ed953f669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparameter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mMymodel\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mparameter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_values' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "Model_path = 'model/kge1.txt'\n",
    "with open(Model_path,'rb') as f:\n",
    "    Mymodel = pickle.load(f)\n",
    "f.close()\n",
    "parameter = {**Mymodel}.values()\n",
    "parameter[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([3, 2])\n"
     ]
    }
   ],
   "source": [
    "a = {'water':2}\n",
    "a = {'seed':3,**a}\n",
    "print(a.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KG增量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from gensim.models import Word2Vec,KeyedVectors,FastText\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import torch\n",
    "import re,os,pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelClassifier:\n",
    "    def __init__(self,label_dict_path='parser/config/labels.txt'):\n",
    "        self.labeldict = {}  # dictionary that maps int to label text\n",
    "        self.labeldictR = {} # maps label text to int\n",
    "        self.load_label_dict(label_dict_path)\n",
    "        #print(self.labeldictR)\n",
    "    def load_label_dict(self,filename):\n",
    "        with open(filename,encoding='UTF-8') as f:\n",
    "            data = f.read().splitlines()\n",
    "        self.labeldict = { i:a.split('\\t')[0] for (i,a) in enumerate(data)}\n",
    "        self.labeldictR = { a:i  for (i,a) in self.labeldict.items()}\n",
    "    def classify(self,string):\n",
    "        pass\n",
    "    def train_update(self, list_mseg, list_mlabel):\n",
    "        pass\n",
    "    \n",
    "class KGClassifier(LabelClassifier):\n",
    "    def __init__(self, label2id_path = 'parser/config/labels.txt'):\n",
    "        #LabelClassifier.__init__(self)\n",
    "        self.label2id = {}\n",
    "        with open(label2id_path,'r') as f:\n",
    "            label2id = f.readlines()\n",
    "        for line in label2id:\n",
    "            line = line.strip().split('\\t')\n",
    "            self.label2id[line[0]] = eval(line[1])\n",
    "        self.id2label = []\n",
    "        for key in self.label2id:\n",
    "            self.id2label.append(key)\n",
    "        self.loadKGE()\n",
    "    def loadKGE(self,Model_path = 'parser/model/kge1.txt'):\n",
    "        with open(Model_path,'rb') as f:\n",
    "            self.Mymodel = pickle.load(f)\n",
    "        f.close()\n",
    "    def online_train_kge(self,L,learning_rate=0.0005,epoch_size=10,saving=False):\n",
    "        '''L sample:[['深圳市 公安局 警员',['公安','深圳']],['广州市 环保局 科员',['环境保护']],…]'''\n",
    "        allfacts = []\n",
    "        for resu in L:\n",
    "            text,labels = resu\n",
    "            for label in labels:\n",
    "                allfacts.append(text+'\\ttext.2.label\\t'+label+'\\n')\n",
    "            for item in text.split():\n",
    "                if item not in self.Mymodel:\n",
    "                    self.Mymodel[item] = torch.Tensor(np.random.rand(len(self.Mymodel['深圳'])))\n",
    "                    self.Mymodel[item].requires_grad = True\n",
    "        LossList = []\n",
    "        parameter = {**self.Mymodel}.values()\n",
    "        optimizer = optim.SGD(parameter,lr=learning_rate)\n",
    "        batch_size = 1\n",
    "        for epoch in range(epoch_size):\n",
    "            epoch_loss = 0\n",
    "            shuffle(allfacts)\n",
    "            list2 = []\n",
    "            for i in range(0, len(allfacts), batch_size):\n",
    "                list2.append(allfacts[i:i+batch_size])\n",
    "            for sub_batch in list2:\n",
    "                optimizer.zero_grad()\n",
    "                liu = self.Loss(sub_batch)\n",
    "                #print('Epoch',epoch,'- Batch Loss:',liu)\n",
    "                epoch_loss += float(liu)\n",
    "                liu.backward(retain_graph=True)\n",
    "                optimizer.step()\n",
    "            #print('Epoch',epoch,'finished. Loss:',epoch_loss)\n",
    "            LossList.append(epoch_loss)\n",
    "        if saving == True:\n",
    "            final = {**Mymodel}\n",
    "            f = open('model/kge_'+time.strftime(\"%Y-%m-%d_%H_%M\", time.localtime()) +'.kge','wb')\n",
    "            pickle.dump(final,f)\n",
    "            f.close()\n",
    "    def kg_text_embd(self,string):\n",
    "        res = string.split()\n",
    "        result = 0\n",
    "        for item in res:\n",
    "            if item not in self.Mymodel:\n",
    "                self.Mymodel[item] = torch.Tensor(np.random.rand(len(self.Mymodel['深圳'])))\n",
    "                self.Mymodel[item].requires_grad = True\n",
    "            result += self.Mymodel[item]\n",
    "        doc_embedding = result/len(res)\n",
    "        return doc_embedding\n",
    "    def TransE(self,he,re,te):\n",
    "        score =  torch.norm(he+re-te)\n",
    "        return score\n",
    "    def Loss(self,L):\n",
    "        loss = 0\n",
    "        for fact in L:\n",
    "            h,r,t = fact.strip().split('\\t')\n",
    "            he = self.kg_text_embd(h)\n",
    "            re = self.Mymodel[r]\n",
    "            te = self.kg_text_embd(t)\n",
    "            loss += self.TransE(he,re,te)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "liu = KGClassifier()\n",
    "print(type(liu.Mymodel))\n",
    "print(('test' in liu.Mymodel))\n",
    "liu.Mymodel['test'] = torch.Tensor(np.random.rand(len(liu.Mymodel['深圳'])))\n",
    "print(('test' in liu.Mymodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手动检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a mini dataset.\n",
      "Time Consuming: 0.21343016624450684 s\n",
      "Labeled resume: 2578 Total resume: 2578 Remained resumes: 0\n"
     ]
    }
   ],
   "source": [
    "from SZlabeler.label_classifier import ExpRuleClassifier\n",
    "import os\n",
    "import time\n",
    "# Testing on a mini dataset.\n",
    "f = open('./final_version.txt','r',encoding='utf-8')\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "data = [item.strip().split()[1] for item in data if ' ' in item]\n",
    "\n",
    "clf = ExpRuleClassifier()\n",
    "toshow = []\n",
    "count = 0\n",
    "print('Testing on a mini dataset.')\n",
    "t0 = time.time()\n",
    "for resume in data:\n",
    "    res_dict = clf.classify(resume)\n",
    "    predict = [label for (label,value) in res_dict.items() if value==True]\n",
    "    '''\n",
    "    if '深圳' in predict:\n",
    "        predict.remove('深圳')'''\n",
    "    if predict == []:\n",
    "        toshow.append(['0',resume,predict])\n",
    "    else:\n",
    "        toshow.append(['1',resume,predict])\n",
    "        count += 1\n",
    "print('Time Consuming:',time.time()-t0,'s')\n",
    "print('Labeled resume:',count,'Total resume:',len(toshow),'Remained resumes:',len(toshow)-count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in toshow:\n",
    "    if line[0]=='0':\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['理工方向1', '深圳1', '军检法机构1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.hybridkeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person 类测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from datetime import date\n",
    "# from Career_Platform.octree.OCtree import CTree\n",
    "#location = os.path.abspath(os.path.dirname(__file__))\n",
    "\n",
    "location = 'SZlabeler'\n",
    "\n",
    "class Experience:\n",
    "    def __init__(self,text, time=None, loc=None, org=None,seg=None,labels=None):\n",
    "        self.text=text\n",
    "        self.time=time\n",
    "        self.organization=org\n",
    "        self.location=loc\n",
    "        self.segmented = seg # segmented string\n",
    "        self.labels = labels # list of labels\n",
    "        self.batch_id =None\n",
    "        \n",
    "class WorkExperience(Experience):\n",
    "    def __init__(self, text, time=None, loc=None, org=None,seg=None,\n",
    "                 labels=None, pos=None):\n",
    "        Experience.__init__(self,text,time,loc,org,seg,labels)\n",
    "        self.position = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    '''Description Here'''\n",
    "    def __init__(self,name,gender='',age=30):\n",
    "        self.name = name # string\n",
    "        self.gender = gender #'W' or 'M'\n",
    "        self.age = age # integer\n",
    "        self.tags = []\n",
    "        self.work_exp = []  # indexed by rid(time)\n",
    "        self.work_labels = []\n",
    "        for item in self.work_exp:\n",
    "            self.work_labels.extend(item.labels)\n",
    "        self.work_labels = list(set(self.work_labels))\n",
    "    def __str__(self):\n",
    "        return '姓名：'+self.name+'，共有'+str(self.__len__())+'条经历；'\n",
    "    \n",
    "    def update_resumes(self,L):\n",
    "        self.work_exp = L\n",
    "        self.work_labels = []\n",
    "        for item in self.work_exp:\n",
    "            self.work_labels.extend(item.labels)\n",
    "        self.work_labels = list(set(self.work_labels))\n",
    "        self.survival()\n",
    "        \n",
    "    def survival(self,query_condition_path = location+'/config/query_condition.json'):\n",
    "        '''construct a survival time dictionary(STD)'''\n",
    "        f = open(query_condition_path,encoding='utf-8')\n",
    "        condition_dict = json.load(f)\n",
    "        f.close()\n",
    "        \n",
    "        self.STD = {}\n",
    "        for key in self.work_labels:\n",
    "            self.STD[key] = [0,(0,0),[],condition_dict[key]['Timelen'],condition_dict[key]['Period'],condition_dict[key]['Now']]\n",
    "        for exp in self.work_exp:\n",
    "            strtuple = exp.time.split('—')\n",
    "            datetuple = [date(int(eval(item)//1),round((eval(item)%1)*100),1) for item in strtuple]\n",
    "            interval = (datetuple[1]-datetuple[0]).days\n",
    "            for key in exp.labels:\n",
    "                self.STD[key][0] += interval\n",
    "                self.STD[key][2].append(datetuple)\n",
    "        for key in self.STD.keys():\n",
    "            self.STD[key][1] = (self.STD[key][2][0][0],self.STD[key][2][-1][1])\n",
    "            self.STD[key][0] = self.STD[key][0]\n",
    "        return self.STD\n",
    "    \n",
    "    def checkbytime(self,year,month,day):\n",
    "        checktime = date(year,month,day)\n",
    "        for exp in self.work_exp:\n",
    "            strtuple = exp.time.split('—')\n",
    "            datetuple = [date(int(eval(item)//1),round((eval(item)%1)*100),1) for item in strtuple]\n",
    "            if checktime>datetuple[0] and checktime<datetuple[1]:\n",
    "                return [exp.text,exp.labels]\n",
    "        return None\n",
    "    \n",
    "    def reply(self,allquery):\n",
    "        '''imageine the Query looks like :\n",
    "        allquery = {\n",
    "        'personal':{'gender':'W','age':(20,50)},\n",
    "        'workexp':{\n",
    "            '基层经历':{'Timelen':730,'Period':(datetime.date(2001, 9, 1), datetime.date(2006, 4, 1)),'Now':False},\n",
    "            '教育':{'Timelen':730,'Now':False}\n",
    "        }\n",
    "        }\n",
    "        在不勾选任何附加项的情况下，返回的Query应为：\n",
    "        allquery = {\n",
    "        'personal':{'gender':None,'age':(0,120)},\n",
    "        'workexp':{\n",
    "            '勾选的标签':{'Timelen':1,'Period':(datetime.date(1949, 10, 1), datetime.date(9999, 10, 1)),'Now':False},\n",
    "        }\n",
    "        }\n",
    "        '''\n",
    "        pquery = allquery['personal']\n",
    "        if pquery['gender'] != None:\n",
    "            if pquery['gender'] != self.gender:\n",
    "                return False\n",
    "        if (self.age < pquery['age'][0]) or (self.age > pquery['age'][1]):\n",
    "            return False\n",
    "        \n",
    "        query = allquery['workexp']\n",
    "        querykeys = list(query.keys())\n",
    "        if set(querykeys).issubset(set(self.work_labels)) == 0:\n",
    "            return False\n",
    "        for key in querykeys:\n",
    "            if self.STD[key][3] == True:\n",
    "                if query[key]['Timelen'] > self.STD[key][0]:\n",
    "                    return False\n",
    "            if self.STD[key][5] == True:\n",
    "                if query[key]['Now']==True:\n",
    "                    if key not in self.work_exp[-1].labels:\n",
    "                        return False\n",
    "            if self.STD[key][4] == True:\n",
    "                flag = 0\n",
    "                for tu in self.STD[key][2]:\n",
    "                    if flag == 1:\n",
    "                        break\n",
    "                    for d in tu:\n",
    "                        if d>query[key]['Period'][0] and d<query[key]['Period'][1]:\n",
    "                            flag = 1\n",
    "                if flag == 0:\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def labelmap(self):\n",
    "        plt.grid(True)\n",
    "        X,Y = [],[]\n",
    "        Ydict = {}\n",
    "        for i,key in enumerate(self.work_labels):\n",
    "            Ydict[key] = i+1\n",
    "        plt.yticks(fontproperties=\"STSong\") \n",
    "        plt.yticks([Ydict[key] for key in self.work_labels],self.work_labels)\n",
    "        for exp in self.work_exp:\n",
    "            strtuple = exp.time.split('—')\n",
    "            numtuple = [self.date2num(zw) for zw in strtuple]\n",
    "            plt.plot([numtuple[0]]*2,[0.5,len(self.work_labels)+0.5],linestyle=':',color='grey')\n",
    "            plt.text(numtuple[0],len(self.work_labels)+0.5,strtuple[0],ha='center')\n",
    "            X.append(numtuple)\n",
    "            Y.append(exp.labels)\n",
    "        for i,timelen in enumerate(X):\n",
    "            for label in Y[i]:\n",
    "                plt.plot(timelen,[Ydict[label]]*len(timelen),linewidth=5.0)\n",
    "        plt.show()\n",
    "                \n",
    "    def date2num(self,text,reverse=False):\n",
    "        if reverse==False:\n",
    "            num = eval(text)\n",
    "            return (num//1+(num%1)/(0.12))\n",
    "        return str(text//1+round((text%1)*12)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "liu = Person('张三')\n",
    "liu.gender = 'W'\n",
    "liu.age = 30\n",
    "#r0 = WorkExperience(time='',labels=[])\n",
    "r1 = WorkExperience(text='某某大学学习',time='1997.08—2001.09',labels=['双一流大学'])\n",
    "r2= WorkExperience(text='深圳龙华区公务员',time='2001.09—2006.04',labels=['深圳','龙华','基层工作'])\n",
    "r3= WorkExperience(text='深圳市党校校长',time='2006.04—2016.10',labels=['深圳','教育'])\n",
    "r4= WorkExperience(text='深圳市人大代表',time='2016.10—2020.09',labels=['深圳','市人大直属'])\n",
    "liu.update_resumes([r1,r2,r3,r4])\n",
    "liu.labelmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'双一流大学': [1492,\n",
       "  (datetime.date(1997, 8, 1), datetime.date(2001, 9, 1)),\n",
       "  [[datetime.date(1997, 8, 1), datetime.date(2001, 9, 1)]],\n",
       "  True,\n",
       "  False,\n",
       "  True],\n",
       " '市人大直属': [1431,\n",
       "  (datetime.date(2016, 10, 1), datetime.date(2020, 9, 1)),\n",
       "  [[datetime.date(2016, 10, 1), datetime.date(2020, 9, 1)]],\n",
       "  True,\n",
       "  False,\n",
       "  True],\n",
       " '教育': [3836,\n",
       "  (datetime.date(2006, 4, 1), datetime.date(2016, 10, 1)),\n",
       "  [[datetime.date(2006, 4, 1), datetime.date(2016, 10, 1)]],\n",
       "  True,\n",
       "  False,\n",
       "  True],\n",
       " '深圳': [6940,\n",
       "  (datetime.date(2001, 9, 1), datetime.date(2020, 9, 1)),\n",
       "  [[datetime.date(2001, 9, 1), datetime.date(2006, 4, 1)],\n",
       "   [datetime.date(2006, 4, 1), datetime.date(2016, 10, 1)],\n",
       "   [datetime.date(2016, 10, 1), datetime.date(2020, 9, 1)]],\n",
       "  True,\n",
       "  False,\n",
       "  True],\n",
       " '基层工作': [1673,\n",
       "  (datetime.date(2001, 9, 1), datetime.date(2006, 4, 1)),\n",
       "  [[datetime.date(2001, 9, 1), datetime.date(2006, 4, 1)]],\n",
       "  True,\n",
       "  False,\n",
       "  True],\n",
       " '龙华': [1673,\n",
       "  (datetime.date(2001, 9, 1), datetime.date(2006, 4, 1)),\n",
       "  [[datetime.date(2001, 9, 1), datetime.date(2006, 4, 1)]],\n",
       "  True,\n",
       "  False,\n",
       "  True]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liu.STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\n",
    "        'personal':{'gender':'W','age':(20,50)},\n",
    "        'workexp':{\n",
    "            #'基层经历':{'Timelen':730,'Period':(datetime.date(2001, 9, 1), datetime.date(2006, 4, 1)),'Now':False},\n",
    "            '教育':{'Timelen':730,'Now':False}\n",
    "        }\n",
    "        }\n",
    "\n",
    "liu.reply(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['深圳市党校校长', ['深圳', '教育']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liu.checkbytime(2015,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
